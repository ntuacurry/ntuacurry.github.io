import streamlit as st
import yfinance as yf
import pandas as pd
from datetime import date
import time 

# ---------------------------------------------------------
# å¾åŸç¨‹å¼ç¢¼è¤‡è£½å¿…è¦çš„è¼”åŠ©å‡½æ•¸å’Œå¸¸é‡ (è·¯å¾‘å·²ä¿®æ­£)
# ---------------------------------------------------------

# é¡è‰²å®šç¾© (å¾åŸç¨‹å¼ç¢¼è¤‡è£½)
WIND_COLORS = {
    "å¼·é¢¨": "rgba(255, 0, 0, 0.5)",
    "äº‚æµ": "rgba(0, 128, 0, 0.5)",
    "é™£é¢¨": "rgba(255, 192, 203, 0.5)",
    "ç„¡é¢¨": "rgba(105, 105, 105, 0.5)"
}

@st.cache_data
def load_stock_map(file_path="è‚¡ç¥¨è³‡æ–™.csv"): 
    """
    è¼‰å…¥è‚¡ç¥¨è³‡æ–™CSVï¼Œä¸¦å»ºç«‹ä»£ç¢¼ã€åç¨±ã€yfinance_ticker çš„å°æ‡‰é—œä¿‚ã€‚
    ç¯©é¸å‡º CFICode = 'ESVUFR' çš„è‚¡ç¥¨ã€‚
    """
    try:
        # ä½¿ç”¨ root_path ä¾†è®€å–ä½æ–¼æ‡‰ç”¨ç¨‹å¼æ ¹ç›®éŒ„çš„ 'è‚¡ç¥¨è³‡æ–™.csv'
        # æ³¨æ„: åœ¨ Streamlit å¤šé é¢çµæ§‹ä¸­ï¼Œç¨‹å¼åŸ·è¡Œçš„ç•¶å‰ç›®éŒ„å¯èƒ½ä¸åŒï¼Œ
        # ä½† Streamlit é€šå¸¸èƒ½æ‰¾åˆ°èˆ‡æ‡‰ç”¨ç¨‹å¼æ–‡ä»¶åœ¨åŒä¸€å±¤çš„è³‡æºæ–‡ä»¶ã€‚
        df = pd.read_csv(file_path, encoding='utf-8', engine='python')
        df.columns = df.columns.str.replace(r'\s+', '', regex=True)
        
        # ğŸ¯ é—œéµæ­¥é©Ÿï¼šç¯©é¸ CFICode
        df_filtered = df[df['CFICode'] == 'ESVUFR'].copy()
            
        stock_map = {} # key: ä»£ç¢¼ (str), value: (åç¨±, å¸‚å ´åˆ¥, yfinance_ticker)
        
        for index, row in df_filtered.iterrows():
            code = str(row['å…¬å¸ä»£è™Ÿ']).strip()
            name = row['å…¬å¸åç¨±'].strip()
            market = str(row['å¸‚å ´åˆ¥']).strip() if not pd.isna(row['å¸‚å ´åˆ¥']) else ""
            
            # è½‰æ›ç‚º yfinance æ ¼å¼ (å‡è¨­å°ç£ä¸Šå¸‚/ä¸Šæ«ƒ)
            if not market: 
                yfinance_ticker = code
            elif market == 'ä¸Šå¸‚':
                yfinance_ticker = f"{code}.TW"
            elif market == 'ä¸Šæ«ƒ':
                yfinance_ticker = f"{code}.TWO"
            else:
                yfinance_ticker = code
            
            # ç¢ºä¿ä»£ç¢¼æ˜¯ç´”æ•¸å­—ï¼Œä¸”ä¸ç‚ºç©º
            if code.isdigit() and code:
                stock_map[code] = (name, market, yfinance_ticker)
                
        return stock_map
        
    except FileNotFoundError:
        st.error(f"éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°æª”æ¡ˆ {file_path}ã€‚è«‹ç¢ºä¿æª”æ¡ˆå·²å­˜åœ¨æ–¼æ‡‰ç”¨ç¨‹å¼çš„æ ¹ç›®éŒ„ã€‚")
        return {}
    except KeyError as e:
        st.error(f"éŒ¯èª¤ï¼šCSV æª”æ¡ˆä¸­æ‰¾ä¸åˆ°å¿…è¦çš„æ¬„ä½: {e}ã€‚è«‹ç¢ºèª Header æ˜¯å¦åŒ…å« 'å…¬å¸ä»£è™Ÿ', 'å…¬å¸åç¨±', 'å¸‚å ´åˆ¥', 'CFICode'ã€‚")
        return {}
    except Exception as e:
        st.error(f"è®€å–æˆ–è™•ç†è‚¡ç¥¨è³‡æ–™æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return {}

# è¼‰å…¥è‚¡ç¥¨ä»£ç¢¼å°æ‡‰è¡¨ (åƒ…é™ ESVUFR é¡åˆ¥)
STOCK_MAP = load_stock_map("../è‚¡ç¥¨è³‡æ–™.csv") # å‡å®š CSV åœ¨æ ¹ç›®éŒ„
# ç¯©é¸å‡º yfinance ticker åˆ—è¡¨
TICKER_LIST = [item[2] for item in STOCK_MAP.values()]
# å»ºç«‹ code -> (name, ticker) çš„åå‘æŸ¥è¡¨
CODE_TO_INFO = {code: (name, ticker) for code, (name, market, ticker) in STOCK_MAP.items()}


@st.cache_data
def load_data(symbol):
    """ä¸‹è¼‰è‚¡ç¥¨è³‡æ–™ (åŒ…å« Volume)ï¼Œä½¿ç”¨ä¸€å¹´é€±æœŸç¢ºä¿è¶³å¤ çš„ MACD æ•¸æ“šã€‚"""
    stock = yf.Ticker(symbol)
    df = stock.history(interval="1d", period="1y", actions=False, auto_adjust=False, back_adjust=False)
    # ç¢ºä¿åªè¿”å›åŒ…å« Open/High/Low/Close/Volume çš„æœ‰æ•ˆæ•¸æ“š
    return df[['Open', 'High', 'Low', 'Close', 'Volume']].dropna()

def resample_weekly_data(df_daily):
    """å°‡æ—¥ K è³‡æ–™è½‰æ›ç‚ºé€± K è³‡æ–™ï¼Œä¿ç•™ä¸å®Œæ•´çš„ç•¶å‰é€±æœŸã€‚"""
    if df_daily.empty:
        return df_daily
        
    # è¨ˆç®— MACD éœ€è¦ Priceï¼ŒPrice ä¾è³´ High/Low/Closeï¼Œæ‰€ä»¥é€± K éœ€è¦å½™æ•´é€™äº›æ•¸æ“š
    weekly_data = df_daily.resample('W').agg({
        'Open': 'first',      
        'High': 'max',        
        'Low': 'min',         
        'Close': 'last', 
        'Volume': 'sum' # æˆäº¤é‡ç¸½å’Œ
    })
    
    return weekly_data[weekly_data['Open'].notna()] 


# ---------------------------------------------------------
# é€±è¶¨å‹¢é¢¨ç®ç¯©é¸é‚è¼¯
# ---------------------------------------------------------
def calculate_weekly_kite(df_daily, yf_ticker):
    """è¨ˆç®—ä¸¦ç¯©é¸ç¬¦åˆã€Œé€±è¶¨å‹¢é¢¨ç®ã€æ¢ä»¶çš„è‚¡ç¥¨ã€‚"""
    
    # 1. è½‰æ›ç‚ºé€± K æ•¸æ“š
    df_weekly = resample_weekly_data(df_daily)
    
    if df_weekly.empty or len(df_weekly) < 2:
        return None

    # 2. è¨ˆç®—æŒ‡æ¨™
    # MACD éœ€è¦ Price
    df_weekly["Price"] = round((df_weekly["High"] + df_weekly["Low"] + 2 * df_weekly["Close"]) / 4, 2)
    df_weekly["EMA12"] = df_weekly["Price"].ewm(span=12, adjust=False).mean()
    df_weekly["EMA26"] = df_weekly["Price"].ewm(span=26, adjust=False).mean()
    df_weekly["DIF"] = df_weekly["EMA12"] - df_weekly["EMA26"]
    df_weekly["MACD"] = df_weekly["DIF"].ewm(span=9, adjust=False).mean()
    df_weekly["MACD_H"] = df_weekly["DIF"] - df_weekly["MACD"] # MACD æŸ±ç‹€åœ–

    # 3. æº–å‚™æœ€æ–°å…©é€±æ•¸æ“š (ç¢ºä¿ MACD æ•¸æ“šä¸ç‚º NaN)
    df_valid = df_weekly.dropna(subset=['MACD_H'])
    if len(df_valid) < 2:
        return None
        
    latest = df_valid.iloc[-1]
    prev = df_valid.iloc[-2]
    
    # 4. è¨ˆç®—æœ€æ–°äº¤æ˜“æ—¥æˆäº¤é‡‘é¡ (ä»¥å„„ç‚ºå–®ä½)
    # æˆäº¤é¡ = (åƒ¹æ ¼*1000)*æˆäº¤é‡/100000000
    
    # å–å¾—æœ€æ–°ä¸€ç­†æ—¥ K æ•¸æ“š
    latest_trade_day = df_daily.iloc[-1]
    
    # åƒ¹æ ¼è¨ˆç®— (Price)
    latest_price = round((latest_trade_day["High"] + latest_trade_day["Low"] + 2 * latest_trade_day["Close"]) / 4, 2)
    
    # è¨ˆç®—åŸºç¤é‡‘é¡ (åƒ¹æ ¼ * æˆäº¤é‡)
    base_amount = latest_price * latest_trade_day["Volume"]
    
    # æ¢ä»¶ 1a: åŸºç¤é‡‘é¡ > 100000 (äº¤æ˜“æ´»èºåº¦åˆç¯©)
    if base_amount <= 100000:
        return None 

    # è¨ˆç®—æˆäº¤é¡ (å„„) = (åŸºç¤é‡‘é¡ * 1000) / 100,000,000 = åŸºç¤é‡‘é¡ / 100,000
    turnover_billion = base_amount / 100000.0

    # æ¢ä»¶ 1b: æœ€æ–°äº¤æ˜“æ—¥çš„æˆäº¤é‡‘é¡å¤§æ–¼1å„„
    cond_turnover = turnover_billion >= 1.0 

    # æ¢ä»¶ 2, 3, 4: MACD ç¯©é¸
    cond_macd_up = latest["MACD_H"] > prev["MACD_H"]     # ç›®å‰æœ€æ–°é€™é€±çš„MACDæŸ± > å‰ä¸€é€±çš„MACDæŸ±
    cond_macd_positive = latest["MACD_H"] > 0                 # ç›®å‰æœ€æ–°é€™é€±çš„MACDæŸ± > 0
    cond_macd_prev_negative = prev["MACD_H"] < 0              # å‰ä¸€é€±çš„MACDæŸ± < 0
    
    if cond_macd_up and cond_macd_positive and cond_macd_prev_negative and cond_turnover:
        return {
            "é€±MACDæŸ± (æœ€æ–°)": latest["MACD_H"],
            "é€±MACDæŸ± (å‰ä¸€é€±)": prev["MACD_H"],
            "æœ€æ–°æ—¥æˆäº¤é¡ (å„„)": turnover_billion,
        }
    else:
        return None

# ---------------------------------------------------------
# Streamlit é é¢ä¸»é«”
# ---------------------------------------------------------

st.set_page_config(page_title="é€±è¶¨å‹¢é¢¨ç®", layout="wide")
st.title("ğŸš€ é€±è¶¨å‹¢é¢¨ç®ç¯©é¸")

st.markdown(r"""
#### ç¯©é¸æ¢ä»¶ (å¿…é ˆåŒæ™‚ç¬¦åˆ)ï¼š
1. **MACD æŸ±è½‰ç´…:** æœ¬é€± MACD æŸ± $\text{(æœ€æ–°)} >$ ä¸Šé€± MACD æŸ± $\text{(å‰ä¸€é€±)}$
2. **MACD æŸ±ç¿»å¤š:** æœ¬é€± MACD æŸ± $\text{(æœ€æ–°)} > 0$
3. **MACD æŸ±åº•èƒŒé›¢:** ä¸Šé€± MACD æŸ± $\text{(å‰ä¸€é€±)} < 0$
4. **æ´»èºåº¦é–€æª»:** æœ€æ–°äº¤æ˜“æ—¥æˆäº¤é‡‘é¡ $\ge 1$ å„„
   (æˆäº¤é¡è¨ˆç®—ä¾æ“šï¼š$\text{æˆäº¤é¡ (å„„)} = \frac{(Price \times Volume \times 1000)}{100,000,000}$ï¼Œå…¶ä¸­ $Price = (High + Low + 2 \times Close) / 4$)
""")

if st.button("é–‹å§‹åŸ·è¡Œç¯©é¸", type="primary"):
    
    if not STOCK_MAP:
        st.error("è‚¡ç¥¨åˆ—è¡¨ç‚ºç©ºï¼Œè«‹æª¢æŸ¥ 'è‚¡ç¥¨è³‡æ–™.csv' æª”æ¡ˆæ˜¯å¦ä½æ–¼æ‡‰ç”¨ç¨‹å¼æ ¹ç›®éŒ„ï¼Œä¸¦ç¢ºèªå…¶ä¸­åŒ…å« CFICode = 'ESVUFR' çš„è‚¡ç¥¨è³‡æ–™ã€‚")
        st.stop()

    results = []
    total_tickers = len(TICKER_LIST)
    progress_bar = st.progress(0, text="åˆå§‹åŒ–...")
    status_text = st.empty()
    
    start_time = time.time()
    
    for i, yf_ticker in enumerate(TICKER_LIST):
        
        # æ›´æ–°é€²åº¦æ¢
        percent_complete = (i + 1) / total_tickers
        progress_bar.progress(percent_complete, text=f"è™•ç†ä¸­: {i+1}/{total_tickers} å€‹ä»£ç¢¼ ({yf_ticker})")
        
        code = yf_ticker.split('.')[0]
        company_name, _ = CODE_TO_INFO.get(code, ('æœªçŸ¥åç¨±', yf_ticker))

        # 1. ä¸‹è¼‰æ•¸æ“š
        daily_data = load_data(yf_ticker)

        if daily_data.empty:
            status_text.markdown(f"è™•ç† **{code} ({company_name})**: âŒ è³‡æ–™ä¸‹è¼‰å¤±æ•—æˆ–ç‚ºç©ºã€‚")
            continue

        # 2. åŸ·è¡Œç¯©é¸é‚è¼¯
        try:
            kite_info = calculate_weekly_kite(daily_data, yf_ticker)
        except Exception as e:
             # åƒ…è¼¸å‡ºéŒ¯èª¤æç¤ºï¼Œä¸ä¸­æ–·æ•´é«”é€²ç¨‹
             status_text.markdown(f"è™•ç† **{code} ({company_name})**: âŒ è¨ˆç®—éŒ¯èª¤ï¼š{e}")
             continue
        
        # 3. è¨˜éŒ„ç¬¦åˆæ¢ä»¶çš„è‚¡ç¥¨
        if kite_info:
            results.append({
                "å…¬å¸ä»£ç¢¼": code,
                "å…¬å¸åç¨±": company_name,
                "YF_TICKER": yf_ticker,
                **kite_info 
            })
            status_text.markdown(f"è™•ç† **{code} ({company_name})**: âœ… **ç¬¦åˆæ¢ä»¶!** (æˆäº¤é¡: {kite_info['æœ€æ–°æ—¥æˆäº¤é¡ (å„„)']:.2f} å„„)")
        else:
            status_text.markdown(f"è™•ç† **{code} ({company_name})**: â¬œ ä¸ç¬¦åˆæ¢ä»¶ã€‚")
        
    # çµæŸè™•ç†
    progress_bar.empty()
    status_text.empty()
    end_time = time.time()
    st.success(f"âœ… ç¯©é¸å®Œæˆï¼å…±è™•ç† {total_tickers} å€‹ä»£ç¢¼ï¼Œè€—æ™‚ {end_time - start_time:.2f} ç§’ã€‚")

    if results:
        # 4. è½‰æ›ç‚º DataFrame ä¸¦æŒ‰æˆäº¤é¡æ’åº
        results_df = pd.DataFrame(results)
        results_df = results_df.sort_values(by="æœ€æ–°æ—¥æˆäº¤é¡ (å„„)", ascending=False)
        
        # 5. é¡¯ç¤ºçµæœ
        st.subheader(f"âœ¨ ç¬¦åˆã€Œé€±è¶¨å‹¢é¢¨ç®ã€æ¢ä»¶çš„è‚¡ç¥¨ ({len(results)} æª”)")
        
        # æ ¼å¼åŒ–é¡¯ç¤º (ä¸é¡¯ç¤º YF_TICKER)
        display_df = results_df.drop(columns=["YF_TICKER"])
        
        st.dataframe(
            display_df.style.format({
                "é€±MACDæŸ± (æœ€æ–°)": "{:.2f}",
                "é€±MACDæŸ± (å‰ä¸€é€±)": "{:.2f}",
                "æœ€æ–°æ—¥æˆäº¤é¡ (å„„)": "{:.2f} å„„"
            }),
            hide_index=True,
            width='stretch'
        )

    else:
        st.warning("ğŸ¥² æ²’æœ‰æ‰¾åˆ°ç¬¦åˆã€Œé€±è¶¨å‹¢é¢¨ç®ã€æ¢ä»¶çš„è‚¡ç¥¨ã€‚")
